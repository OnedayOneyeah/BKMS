{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract Lyrics Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chloe/opt/miniconda3/envs/BKMS/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from transformers import AutoTokenizer\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import scipy as sp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import dataset\n",
    "data = pd.read_csv('./spotify_data.csv', index_col=[0])\n",
    "lyrics_data = pd.DataFrame(data['lyrics'])\n",
    "lyrics_data['embedding'] = ''\n",
    "lyrics_data['lyrics'] = lyrics_data['lyrics'].apply(lambda e: e.replace('\"',''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading config.json: 100%|██████████| 1.00k/1.00k [00:00<00:00, 214kB/s]\n",
      "Downloading tokenizer_config.json: 100%|██████████| 294/294 [00:00<00:00, 103kB/s]\n",
      "Downloading vocab.json: 100%|██████████| 798k/798k [00:00<00:00, 1.22MB/s]\n",
      "Downloading merges.txt: 100%|██████████| 456k/456k [00:00<00:00, 2.15MB/s]\n",
      "Downloading (…)cial_tokens_map.json: 100%|██████████| 239/239 [00:00<00:00, 165kB/s]\n",
      "Downloading tokenizer.json: 100%|██████████| 1.36M/1.36M [00:00<00:00, 3.30MB/s]\n",
      "Downloading pytorch_model.bin: 100%|██████████| 329M/329M [00:20<00:00, 16.2MB/s] \n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at j-hartmann/emotion-english-distilroberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (674 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lyrics</th>\n",
       "      <th>embedding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>Aah Aah The games you played were never fun Yo...</td>\n",
       "      <td>[0.11173111, 0.5557255, 0.8257218, 0.35561693,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>445</th>\n",
       "      <td>The lights go out and I can't be saved Tides t...</td>\n",
       "      <td>[0.010673863, 0.5355972, 0.69947267, 0.1620012...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>763</th>\n",
       "      <td>'Cause you're a sky, 'cause you're a sky full ...</td>\n",
       "      <td>[0.26425898, 0.68403536, 0.20476605, 0.3347745...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>856</th>\n",
       "      <td>I will not make the same mistakes that you did...</td>\n",
       "      <td>[-0.4957115, 0.19850674, 0.38352963, 0.2268695...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1169</th>\n",
       "      <td>Heyy Heeey Heey Your lipstick stains On the fr...</td>\n",
       "      <td>[0.54356205, 0.51118445, 0.26775378, 0.2068563...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16203</th>\n",
       "      <td>Yeah, you! Yeah, you! I used to wanna be Livin...</td>\n",
       "      <td>[0.5549803, 0.7041393, 0.281284, 0.30927595, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16284</th>\n",
       "      <td>If you don't wanna see me Did a full 180, craz...</td>\n",
       "      <td>[-0.027963923, 0.4214012, 0.027016114, 0.36592...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16771</th>\n",
       "      <td>Nah, nah, nah Cake by the ocean Oh, no See you...</td>\n",
       "      <td>[0.5492718, 0.5855223, 0.12780374, 0.22220916,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17046</th>\n",
       "      <td>Come on, come on, turn the radio on It's Frida...</td>\n",
       "      <td>[0.3522463, 0.41048434, 0.06727339, 0.12759277...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18402</th>\n",
       "      <td>Clock strikes upon the hour And the sun begins...</td>\n",
       "      <td>[0.355829, 0.3660182, 0.47026837, 0.5766581, -...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>317 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  lyrics  \\\n",
       "160    Aah Aah The games you played were never fun Yo...   \n",
       "445    The lights go out and I can't be saved Tides t...   \n",
       "763    'Cause you're a sky, 'cause you're a sky full ...   \n",
       "856    I will not make the same mistakes that you did...   \n",
       "1169   Heyy Heeey Heey Your lipstick stains On the fr...   \n",
       "...                                                  ...   \n",
       "16203  Yeah, you! Yeah, you! I used to wanna be Livin...   \n",
       "16284  If you don't wanna see me Did a full 180, craz...   \n",
       "16771  Nah, nah, nah Cake by the ocean Oh, no See you...   \n",
       "17046  Come on, come on, turn the radio on It's Frida...   \n",
       "18402  Clock strikes upon the hour And the sun begins...   \n",
       "\n",
       "                                               embedding  \n",
       "160    [0.11173111, 0.5557255, 0.8257218, 0.35561693,...  \n",
       "445    [0.010673863, 0.5355972, 0.69947267, 0.1620012...  \n",
       "763    [0.26425898, 0.68403536, 0.20476605, 0.3347745...  \n",
       "856    [-0.4957115, 0.19850674, 0.38352963, 0.2268695...  \n",
       "1169   [0.54356205, 0.51118445, 0.26775378, 0.2068563...  \n",
       "...                                                  ...  \n",
       "16203  [0.5549803, 0.7041393, 0.281284, 0.30927595, -...  \n",
       "16284  [-0.027963923, 0.4214012, 0.027016114, 0.36592...  \n",
       "16771  [0.5492718, 0.5855223, 0.12780374, 0.22220916,...  \n",
       "17046  [0.3522463, 0.41048434, 0.06727339, 0.12759277...  \n",
       "18402  [0.355829, 0.3660182, 0.47026837, 0.5766581, -...  \n",
       "\n",
       "[317 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define model\n",
    "from transformers import RobertaTokenizer, RobertaModel, RobertaConfig, pipeline\n",
    "import torch\n",
    "\n",
    "config = RobertaConfig.from_pretrained(\"j-hartmann/emotion-english-distilroberta-base\")\n",
    "config.output_hidden_states = True\n",
    "tok = RobertaTokenizer.from_pretrained(\"j-hartmann/emotion-english-distilroberta-base\")\n",
    "model = RobertaModel.from_pretrained(\"j-hartmann/emotion-english-distilroberta-base\", config=config)\n",
    "\n",
    "# extract embedding\n",
    "lyrics_data['embedding'] = lyrics_data['lyrics'].apply(lambda e: np.array(model(torch.tensor([tok.encode(e)[:512]])).pooler_output.squeeze().detach()))\n",
    "\n",
    "# lyrics_data['embedding'] = lyrics_data['lyrics'].apply(lambda e: model(torch.tensor([tok.encode(e)])).pooler_output.squeeze())\n",
    "lyrics_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('./lyrics_embedding.pkl', 'wb') as f:\n",
    "    pickle.dump(lyrics_data, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1367c8c4473d3265912c8d7e3cdd5911d2a91ae2eeda60059a3a8b4e60ae8f13"
  },
  "kernelspec": {
   "display_name": "Python 3.8.18 ('BKMS')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
