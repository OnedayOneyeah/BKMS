{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classifier\n",
    "- similarity score 1: diary textual embedding - lyrics embedding\n",
    "- similarity score 2: lyrics emotion score - diary emotion score\n",
    "- supplementary score: music feature (0,1) - diary emotion score(→0,1 mapped) if same ⇒ bonus otherwise -)\n",
    "- total score = similarity score 1+ similarity score 2 - supplmentary score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pinecone, torch, torch.nn as nn\n",
    "from transformers import RobertaTokenizer, RobertaModel, RobertaConfig, pipeline\n",
    "\n",
    "# Redefine classifier layer\n",
    "# source code: https://github.com/huggingface/transformers/blob/84ea427f460ffc8d2ddc08a341ccda076c24fc1f/src/transformers/models/roberta/modeling_roberta.py#L1443\n",
    "# config: https://huggingface.co/michellejieli/emotion_text_classifier/blob/main/config.json\n",
    "\n",
    "class RobertaClassificationHead(nn.Module):\n",
    "    \"\"\"Head for sentence-level classification tasks.\"\"\"\n",
    "\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.dense = nn.Linear(config.hidden_size, config.hidden_size)\n",
    "        classifier_dropout = (\n",
    "            config.classifier_dropout if config.classifier_dropout is not None else config.hidden_dropout_prob\n",
    "        )\n",
    "        self.dropout = nn.Dropout(classifier_dropout)\n",
    "        self.out_proj = nn.Linear(config.hidden_size, 28) # config.num_labels\n",
    "\n",
    "    def forward(self, features, **kwargs):\n",
    "        # x = features[:, 0, :]  # take <s> token (equiv. to [CLS])\n",
    "        x = features\n",
    "        x = self.dropout(x)\n",
    "        x = self.dense(x)\n",
    "        x = torch.tanh(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.out_proj(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Classifier:\n",
    "    def __init__(self, lyrics_db_index_name: str, features_db_index_name):\n",
    "\n",
    "        # db\n",
    "        API_KEY = \"12dfbe87-05b3-4243-bb22-e69d329f18ed\"\n",
    "        ENVIRONMENT = \"gcp-starter\"\n",
    "        pinecone.init(api_key = API_KEY, environment = ENVIRONMENT)\n",
    "        self.pinecone_db_lyrics = pinecone.Index(lyrics_db_index_name) # Access the data through 'pinecone_db' object\n",
    "        self.pinecone_db_features = pinecone.Index(features_db_index_name)\n",
    "\n",
    "        # vars\n",
    "        self.total_score = 0.0\n",
    "    \n",
    "    def __call__(self, diary_text: str):        \n",
    "        \n",
    "        # LM\n",
    "        config = RobertaConfig.from_pretrained(\"j-hartmann/emotion-english-distilroberta-base\")\n",
    "        config.output_hidden_states = True\n",
    "        config.num_labels = 7\n",
    "        tok = RobertaTokenizer.from_pretrained(\"j-hartmann/emotion-english-distilroberta-base\")\n",
    "        model = RobertaModel.from_pretrained(\"j-hartmann/emotion-english-distilroberta-base\", config=config)\n",
    "        \n",
    "        # extract embedding\n",
    "        diary_text = torch.tensor([tok.encode(diary_text)])\n",
    "        self.diary_embedding = model(diary_text).pooler_output.squeeze()\n",
    "\n",
    "        # get emotion score\n",
    "        self.classifier = RobertaClassificationHead(config)\n",
    "        self.diary_emotion_scores = self.clasifier(self.diary_embedding)\n",
    "\n",
    "        # self.diary_emotion_scores = {}\n",
    "        # self.diary_emotion_scores['emo'] = config.id2label[int(emotion_scores.argmax())]\n",
    "\n",
    "        # for i in range(emotion_scores):\n",
    "        #     self.diary_emotion_scores[i] = emotion_scores[i]\n",
    "\n",
    "    def compute_scores(self, max_k=100, include_values = True):\n",
    "        s1_vecs, s1_scores, selected_ids = self.compute_s1(max_k, include_values)\n",
    "        lyrics_emotion_scores, s2_scores = self.compute_s2(s1_vecs)\n",
    "\n",
    "        s1s2_scores = torch.mul(s1_scores, s2_scores) # elementwise multiplcation # 100\n",
    "        ss = self.compute_ss(self, selected_ids, include_values)\n",
    "        \n",
    "        total_score = torch.mul(s1s2_scores, ss)\n",
    "\n",
    "        return total_score, selected_ids\n",
    "\n",
    "\n",
    "    def compute_s1(self, max_k = 100, include_values = True):\n",
    "        '''\n",
    "        compute similarity score (1) between diary textual embedding and lyrics embedding.\n",
    "        The dimension of both embeddings is 768.\n",
    "        '''\n",
    "\n",
    "        # Retrieve\n",
    "        s1 = self.pinecone_db_lyrics.query(\n",
    "        vector=self.diary_embedding,\n",
    "        top_k=max_k,\n",
    "        include_values = include_values\n",
    "        )['matches'] # [{id,score,value}, {id,score,value}...]\n",
    "\n",
    "        s1_vecs = {} # {id1: value, id2: value, ...}\n",
    "        s1_scores = [] # {id1: s1_score, id2: s1_score, ...}\n",
    "        selected_ids = []\n",
    "\n",
    "        for element in s1:\n",
    "            s1_vecs[element['id']] = torch.tensor(element['value'])\n",
    "            s1_scores.append(torch.tensor(element['score']))\n",
    "            selected_ids.append(element['id'])\n",
    "\n",
    "        s1_scores = torch.stack(s1_scores, axis = 1) # 1 x 100\n",
    "\n",
    "        return s1_vecs, s1_scores, selected_ids\n",
    "        \n",
    "    def compute_s2(self, s1_vecs):\n",
    "        '''\n",
    "        compute similarity score (2) between diary emotion score and lyrics emotion score.\n",
    "        The dimension of both scores is 7.\n",
    "        '''\n",
    "        \n",
    "        lyrics_emotion_scores = []\n",
    "\n",
    "        for i in s1_vecs.keys():\n",
    "            lyrics_emotion_scores.append(self.classifier(s1_vecs[i]))\n",
    "        \n",
    "        lyrics_emotion_scores = torch.stack(lyrics_emotion_scores, axis = 0)\n",
    "        s2_scores = torch.dot(self.diary_emotion_score.unsqueeze(0), lyrics_emotion_scores.transpose()) # 1 x 28, 28 x 100 => 1 x 100\n",
    "        \n",
    "        return lyrics_emotion_scores, s2_scores\n",
    "\n",
    "    def compute_ss(self, selected_ids, include_values):\n",
    "        '''\n",
    "        project the music and lyrics featues to binary emotion classes and compute supplementary scores\n",
    "        '''\n",
    "\n",
    "        scores_map = [0,0,0]\n",
    "        for i, score in enumerate(self.diary_emotion_scores):\n",
    "            if i in [0,1,2,5]:\n",
    "                scores_map[0] += score\n",
    "            elif i in [3]:\n",
    "                scores_map[1] += score\n",
    "            else:\n",
    "                scores_map[2] += score\n",
    "\n",
    "        diary_label = int(scores_map.argmax())\n",
    "        diary_score = scores_map[diary_label]\n",
    "\n",
    "        # Retrieve\n",
    "        ss = [] # 100\n",
    "\n",
    "        for id in selected_ids:\n",
    "            ss = self.pinecone_db_features.query(\n",
    "                id = id,\n",
    "                include_values = include_values\n",
    "            )['matches'] # [{id,score,value}]\n",
    "            \n",
    "            label = ss[0]['value'][0]  # label(0/1/2) : -/+/.\n",
    "\n",
    "            if label in [0,1,2,5]: # anger, disgust, fear, sadness\n",
    "                label = 0\n",
    "            elif label in [3]: # joy\n",
    "                label = 1\n",
    "            else: # neutral, surprise\n",
    "                label = 2\n",
    "            \n",
    "            s = 1 if diary_label == label else -1\n",
    "            ss.append(s*diary_score)\n",
    "            \n",
    "        ss = torch.tensor(ss)        \n",
    "\n",
    "        return ss\n",
    "    \n",
    "    def return_topk_music(self, scores, selected_ids, top_k = 5):\n",
    "        idxs = torch.argmax(scores, top_n = top_k).to_numpy()\n",
    "        topk_music_ids = selected_ids[idxs]\n",
    "        \n",
    "        return topk_music_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example\n",
    "lyrics_db_index_name = 'your lyrics db index name'\n",
    "features_db_index_name = 'your features db index name'\n",
    "\n",
    "classifier = Classifier(lyrics_db_index_name, features_db_index_name)\n",
    "classifier('I mean I just needed a little sympathy, but no one gave me a single comfort word.')\n",
    "scores, selected_ids = classifier.compute_scores()\n",
    "topk_music_ids = classifier.return_topk_music(scores, selected_ids, top_k = 10) \n",
    "\n",
    "# You can retrieve the music from the pinecone db by using index afterwards."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1367c8c4473d3265912c8d7e3cdd5911d2a91ae2eeda60059a3a8b4e60ae8f13"
  },
  "kernelspec": {
   "display_name": "Python 3.8.18 ('BKMS')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
