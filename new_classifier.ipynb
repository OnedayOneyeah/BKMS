{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classifier\n",
    "- similarity score 1 [0,0.5]: diary textual embedding - lyrics embedding\n",
    "- similarity score 2 [0,0.5]: s2 main [0,0.375] + s2 sub [0, 0.125]\n",
    "- s2 main [0,0.375]: diary emotion embedding - lyrics emotion embedding\n",
    "- s2 sub [0, 0.125]: music feature label (0,1,2) = query emotion score (0,1,2)\n",
    "- total score = similarity score 1 [0,0.5] + similarity score 2 [0,0.5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<수정할 사항>\n",
    "- encoder 추가: textual encoder\n",
    "- pinecone db 3개: lyrics textual embedding / lyrics emotional embedding / music feature scores\n",
    "- s2 수정: compute s2, compute ss, compute score method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chloe/opt/miniconda3/envs/BKMS/lib/python3.8/site-packages/pinecone/index.py:4: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm\n"
     ]
    }
   ],
   "source": [
    "import pinecone, torch, torch.nn as nn\n",
    "from transformers import RobertaTokenizer, RobertaModel, RobertaConfig, pipeline, RobertaForSequenceClassification\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(384,)\n"
     ]
    }
   ],
   "source": [
    "# test encoders\n",
    "from sentence_transformers import SentenceTransformer\n",
    "sentences = \"This is an example sentence\"\n",
    "\n",
    "model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')\n",
    "embeddings = model.encode(sentences)\n",
    "print(embeddings.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 5])\n",
      "tensor([[1., 2., 3., 1., 2.]])\n",
      "tensor([[4., 5., 6., 8., 9.],\n",
      "        [7., 8., 9., 1., 2.]])\n",
      "tensor([[4., 5., 6., 8., 9.],\n",
      "        [7., 8., 9., 1., 2.]])\n",
      "Cosine similarity: [0.8930478  0.89445674]\n"
     ]
    }
   ],
   "source": [
    "# test cosine similarity\n",
    "from sklearn.metrics.pairwise import cosine_similarity, cosine_distances\n",
    "import numpy as np\n",
    "import torch\n",
    "# Define two vectors\n",
    "vector1 = torch.Tensor([1, 2, 3,1,2])\n",
    "vector2 = torch.Tensor([[4, 5, 6,8,9], [7,8,9,1,2]])\n",
    "print(vector2.shape)\n",
    "vector1 = vector1.reshape(1, -1)\n",
    "print(vector1)\n",
    "print(vector2)\n",
    "vector2 = vector2.reshape(len(vector2), -1)\n",
    "print(vector2)\n",
    "\n",
    "# Compute cosine similarity and cosine distance\n",
    "similarity = cosine_similarity(vector1, vector2)\n",
    "# distance = cosine_distances([vector1], [vector2])\n",
    "\n",
    "print(\"Cosine similarity:\", similarity.squeeze())\n",
    "# print(\"Cosine distance:\", distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Redefine classifier layer\n",
    "# source code: https://github.com/huggingface/transformers/blob/84ea427f460ffc8d2ddc08a341ccda076c24fc1f/src/transformers/models/roberta/modeling_roberta.py#L1443\n",
    "# config: https://huggingface.co/michellejieli/emotion_text_classifier/blob/main/config.json\n",
    "# not used\n",
    "\n",
    "class RobertaClassificationHead(nn.Module):\n",
    "    \"\"\"Head for sentence-level classification tasks.\"\"\"\n",
    "\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.dense = nn.Linear(config.hidden_size, config.hidden_size)\n",
    "        classifier_dropout = (\n",
    "            config.classifier_dropout if config.classifier_dropout is not None else config.hidden_dropout_prob\n",
    "        )\n",
    "        self.dropout = nn.Dropout(classifier_dropout)\n",
    "        self.out_proj = nn.Linear(config.hidden_size, 7) # config.num_labels\n",
    "\n",
    "    def forward(self, features, **kwargs):\n",
    "        # x = features[:, 0, :]  # take <s> token (equiv. to [CLS])\n",
    "        x = features\n",
    "        x = self.dropout(x)\n",
    "        x = self.dense(x)\n",
    "        x = torch.tanh(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.out_proj(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Classifier:\n",
    "    def __init__(self, lyrics_text_db_index_name: str, lyrics_emo_db_index_name: str, features_db_index_name: str):\n",
    "\n",
    "        # db\n",
    "        API_KEY = \"12dfbe87-05b3-4243-bb22-e69d329f18ed\"\n",
    "        ENVIRONMENT = \"gcp-starter\"\n",
    "        pinecone.init(api_key = API_KEY, environment = ENVIRONMENT)\n",
    "        self.pinecone_db_lyrics_text = pinecone.Index(lyrics_text_db_index_name) # Access the data through 'pinecone_db' object\n",
    "        self.pinecone_db_lyrics_emo = pinecone.Index(lyrics_emo_db_index_name) \n",
    "        self.pinecone_db_features = pinecone.Index(features_db_index_name)\n",
    "\n",
    "        # vars\n",
    "        self.total_score = 0.0\n",
    "    \n",
    "    def __call__(self, diary_text: str):    \n",
    "\n",
    "        # extract embedding\n",
    "        diary_text = torch.tensor([tok.encode(diary_text)])  \n",
    "        \n",
    "        ## textual embedding\n",
    "        model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')\n",
    "        self.diary_text_embedding = model.encode(diary_text) # d: 384, dtype: torch FloatTensor\n",
    "\n",
    "        ## emotional embedding\n",
    "        config = RobertaConfig.from_pretrained(\"j-hartmann/emotion-english-distilroberta-base\")\n",
    "        config.output_hidden_states = True\n",
    "        config.num_labels = 7\n",
    "        tok = RobertaTokenizer.from_pretrained(\"j-hartmann/emotion-english-distilroberta-base\")\n",
    "        model = RobertaModel.from_pretrained(\"j-hartmann/emotion-english-distilroberta-base\", config=config)\n",
    "        self.diary_emo_embedding = model(diary_text).pooler_output.squeeze() # d: 786, dtype: torch FloatTensor\n",
    "\n",
    "        # get emotion score and classify\n",
    "        self.classifier = RobertaForSequenceClassification.from_pretrained(\"j-hartmann/emotion-english-distilroberta-base\", config=config).classifier\n",
    "        self.diary_emotion_scores = self.clasifier(self.diary_emo_embedding).argmax()\n",
    "        if self.diary_emotion_scores in [0,1,2,5]: # anger, disgust, fear, sadness\n",
    "            self.diary_emotion_scores = 0\n",
    "        elif self.diary_emotion_scores in [3]: # joy\n",
    "            self.diary_emotion_scores = 1\n",
    "        else: # neutral, surprise\n",
    "            self.diary_emotion_scores = 2\n",
    "\n",
    "\n",
    "    def compute_scores(self, max_k=100, include_values = True):\n",
    "\n",
    "        # get score\n",
    "        s1_scores, selected_ids = self.compute_s1(max_k, include_values)\n",
    "        s2_scores = self.compute_s2(selected_ids)\n",
    "\n",
    "        # scaling\n",
    "        total_score = s1_scores * 0.5 + s2_scores * 0.5 # s1_scores.shape: (1,100), s2_scores.shape: (1,100)\n",
    "\n",
    "        return total_score, selected_ids\n",
    "\n",
    "\n",
    "    def compute_s1(self, max_k = 100, include_values = True):\n",
    "        '''\n",
    "        compute similarity score (1) between diary textual embedding and lyrics textual embedding.\n",
    "        The dimension of both embeddings is 384.\n",
    "        '''\n",
    "\n",
    "        # Retrieve\n",
    "        s1 = self.pinecone_db_lyrics.query(\n",
    "        vector=self.diary_text_embedding,\n",
    "        top_k=max_k,\n",
    "        include_values = include_values\n",
    "        )['matches'] # [{id,score,value}, {id,score,value}...]\n",
    "\n",
    "        # s1_vecs = {} # {id1: value, id2: value, ...}\n",
    "        s1_scores = [] # {id1: s1_score, id2: s1_score, ...}\n",
    "        selected_ids = []\n",
    "\n",
    "        for element in s1:\n",
    "            # s1_vecs[element['id']] = torch.tensor(element['value'])\n",
    "            s1_scores.append(torch.tensor(element['score']))\n",
    "            selected_ids.append(element['id'])\n",
    "\n",
    "        s1_scores = torch.stack(s1_scores, axis = 1) # 1 x 100 (max_k)\n",
    "\n",
    "        return s1_scores, selected_ids\n",
    "        \n",
    "    def compute_s2(self, selected_ids):\n",
    "        '''\n",
    "        compute similarity score (2) the sum of s1 main and s2 sub. Each of them scales to the ranges of [0, 0.375] and [0, 0.125].\n",
    "        '''\n",
    "\n",
    "        return self.compute_s2_main(selected_ids = selected_ids)*0.75 + self.compute_s2_sub(selected_ids = selected_ids)*0.25\n",
    "        \n",
    "\n",
    "    def compute_s2_main(self, selected_ids, include_values = True):\n",
    "        '''\n",
    "        compute similarity score between diary emotion embedding and lyrics emotion embedding.\n",
    "        The dimension of both embeddings is 786.\n",
    "        It scales to [0, 0.375].\n",
    "        '''\n",
    "\n",
    "        # Retrieve\n",
    "        s2_main = [] # 100\n",
    "        \n",
    "        for id in selected_ids:\n",
    "            s2_main.append(self.pinecone_db_lyrics_emo.query(\n",
    "                id = id,\n",
    "                include_values = include_values\n",
    "            )['matches']['value']) # [embs, embs, ...], (100, 768)\n",
    "        \n",
    "        s2_main = torch.FloatTensor(s2_main) # (100,768)\n",
    "        \n",
    "        return cosine_similarity(self.diary_emo_embedding.reshape(1,-1), s2_main.T) # (1,768) x (768, 100) =>  1 x 100 \n",
    "\n",
    "    def compute_s2_sub(self, selected_ids, include_values = True):\n",
    "        '''\n",
    "        indicator function for music feature. \n",
    "        if the music feature label (0,1,2) matches the query emotion label (0,1,2), then 1 otherwise 0.\n",
    "        It scalse to [0, 0.125]\n",
    "        '''\n",
    "\n",
    "        # Retrieve\n",
    "        s2_sub = [] # 100\n",
    "\n",
    "        for id in selected_ids:\n",
    "            s2_sub.append(self.pinecone_db_features.query(\n",
    "                id = id,\n",
    "                include_values = include_values,\n",
    "            )['matches']['values']) # [label, label, ...] (100,1)\n",
    "\n",
    "        s2_sub = torch.FloatTensor(s2_sub).reshape(1,100) # (1,100)\n",
    "        s2_sub = torch.eq(torch.ones(s2_sub.shape[1])*self.diary_emotion_scores, s2_sub)*1\n",
    "        \n",
    "        return s2_sub # (1,100)\n",
    "             \n",
    "    \n",
    "    def return_topk_music(self, scores, selected_ids, top_k = 5):\n",
    "        idxs = torch.argmax(scores, top_n = top_k).to_numpy()\n",
    "        topk_music_ids = selected_ids[idxs]\n",
    "        \n",
    "        return topk_music_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example\n",
    "lyrics_db_index_name = 'your lyrics db index name'\n",
    "features_db_index_name = 'your features db index name'\n",
    "\n",
    "classifier = Classifier(lyrics_db_index_name, features_db_index_name)\n",
    "classifier('I mean I just needed a little sympathy, but no one gave me a single comfort word.')\n",
    "scores, selected_ids = classifier.compute_scores()\n",
    "topk_music_ids = classifier.return_topk_music(scores, selected_ids, top_k = 10) \n",
    "\n",
    "# You can retrieve the music from the pinecone db by using index afterwards."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1367c8c4473d3265912c8d7e3cdd5911d2a91ae2eeda60059a3a8b4e60ae8f13"
  },
  "kernelspec": {
   "display_name": "Python 3.8.18 ('BKMS')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
